{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56e3585f-36a2-4433-a5e9-ac7ae48c0c61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing problematic properties...\n",
      "  Unset: fs.s3a.threads.keepalivetime\n",
      "  Unset: hadoop.security.groups.shell.command.timeout\n",
      "  Unset: hadoop.service.shutdown.timeout\n",
      "  Unset: yarn.resourcemanager.delegation-token-renewer.thread-timeout\n",
      "  Unset: yarn.federation.gpg.webapp.connect-timeout\n",
      "  Unset: yarn.federation.gpg.webapp.read-timeout\n",
      "  Unset: fs.s3a.retry.interval\n",
      "  Unset: fs.s3a.retry.throttle.interval\n",
      "  Unset: fs.s3a.connection.ttl\n",
      "  Unset: fs.s3a.multipart.purge.age\n",
      "  Set fs.s3a.threads.keepalivetime = 60\n",
      "  Set hadoop.security.groups.shell.command.timeout = 0\n",
      "  Set fs.s3a.retry.interval = 500\n",
      "  Set fs.s3a.retry.throttle.interval = 100\n",
      "  Set fs.s3a.connection.ttl = 300000\n",
      "\n",
      "Setting MinIO configuration...\n",
      "  Set fs.s3a.endpoint = http://minio:9000\n",
      "  Set fs.s3a.access.key = admin\n",
      "  Set fs.s3a.secret.key = password\n",
      "  Set fs.s3a.path.style.access = true\n",
      "  Set fs.s3a.impl = org.apache.hadoop.fs.s3a.S3AFileSystem\n",
      "  Set fs.s3a.connection.ssl.enabled = false\n",
      "  Set fs.s3a.connection.timeout = 60000\n",
      "  Set fs.s3a.socket.timeout = 60000\n",
      "  Set fs.s3a.connection.establish.timeout = 5000\n",
      "\n",
      "Configuration complete!\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"SEC_Filings_Processor\") \\\n",
    "    .config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-aws:3.3.2\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "hadoop_conf = spark._jsc.hadoopConfiguration()\n",
    "\n",
    "# List of properties that might have duration strings\n",
    "duration_props = [\n",
    "    \"fs.s3a.threads.keepalivetime\",\n",
    "    \"hadoop.security.groups.shell.command.timeout\",\n",
    "    \"hadoop.service.shutdown.timeout\",\n",
    "    \"yarn.resourcemanager.delegation-token-renewer.thread-timeout\", \n",
    "    \"yarn.federation.gpg.webapp.connect-timeout\",\n",
    "    \"yarn.federation.gpg.webapp.read-timeout\",\n",
    "    \"fs.s3a.retry.interval\",\n",
    "    \"fs.s3a.retry.throttle.interval\",\n",
    "    \"fs.s3a.connection.ttl\",\n",
    "    \"fs.s3a.multipart.purge.age\"\n",
    "]\n",
    "\n",
    "print(\"Clearing problematic properties...\")\n",
    "\n",
    "hadoop_conf.set(\n",
    "    \"fs.s3a.aws.credentials.provider\",\n",
    "    \"org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider\"\n",
    ")\n",
    "for prop in duration_props:\n",
    "    hadoop_conf.unset(prop)\n",
    "    print(f\"  Unset: {prop}\")\n",
    "\n",
    "# setting them with numeric values where needed\n",
    "numeric_props = {\n",
    "    \"fs.s3a.threads.keepalivetime\": \"60\",  # seconds as number\n",
    "    \"hadoop.security.groups.shell.command.timeout\": \"0\",  # 0 seconds\n",
    "    \"fs.s3a.retry.interval\": \"500\",  # milliseconds\n",
    "    \"fs.s3a.retry.throttle.interval\": \"100\",  # milliseconds\n",
    "    \"fs.s3a.connection.ttl\": \"300000\",  # 5 minutes in ms\n",
    "}\n",
    "\n",
    "for prop, value in numeric_props.items():\n",
    "    hadoop_conf.set(prop, value)\n",
    "    print(f\"  Set {prop} = {value}\")\n",
    "\n",
    "# Configure MinIO\n",
    "minio_configs = {\n",
    "    \"fs.s3a.endpoint\": \"http://minio:9000\",\n",
    "    \"fs.s3a.access.key\": \"admin\",\n",
    "    \"fs.s3a.secret.key\": \"password\", \n",
    "    \"fs.s3a.path.style.access\": \"true\",\n",
    "    \"fs.s3a.impl\": \"org.apache.hadoop.fs.s3a.S3AFileSystem\",\n",
    "    \"fs.s3a.connection.ssl.enabled\": \"false\",\n",
    "    \"fs.s3a.connection.timeout\": \"60000\",\n",
    "    \"fs.s3a.socket.timeout\": \"60000\",\n",
    "    \"fs.s3a.connection.establish.timeout\": \"5000\",\n",
    "}\n",
    "\n",
    "print(\"\\nSetting MinIO configuration...\")\n",
    "for key, value in minio_configs.items():\n",
    "    hadoop_conf.set(key, value)\n",
    "    print(f\"  Set {key} = {value}\")\n",
    "\n",
    "print(\"\\nConfiguration complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99e6016e-6aee-4f14-a119-a7271574b1ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, split, explode, udf, regexp_extract\n",
    "from pyspark.sql.types import StringType\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "# s3a://raw-data/sec-edgar-filings-raw/AAPL/10-K/0000320193-24-000123.txt -- path\n",
    "path = \"s3a://raw-data/sec-edgar-filings-raw/*/*/*\"\n",
    "\n",
    "raw_df = spark.sparkContext.wholeTextFiles(path).toDF([\"filepath\", \"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96adee96-3faa-464c-a61b-ec68c5ac1c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|            filepath|             content|\n",
      "+--------------------+--------------------+\n",
      "|s3a://raw-data/se...|<SEC-DOCUMENT>000...|\n",
      "|s3a://raw-data/se...|<SEC-DOCUMENT>000...|\n",
      "|s3a://raw-data/se...|<SEC-DOCUMENT>000...|\n",
      "|s3a://raw-data/se...|<SEC-DOCUMENT>000...|\n",
      "|s3a://raw-data/se...|<SEC-DOCUMENT>000...|\n",
      "|s3a://raw-data/se...|<SEC-DOCUMENT>000...|\n",
      "|s3a://raw-data/se...|<SEC-DOCUMENT>000...|\n",
      "|s3a://raw-data/se...|<SEC-DOCUMENT>000...|\n",
      "|s3a://raw-data/se...|<SEC-DOCUMENT>000...|\n",
      "|s3a://raw-data/se...|<SEC-DOCUMENT>000...|\n",
      "|s3a://raw-data/se...|<SEC-DOCUMENT>000...|\n",
      "|s3a://raw-data/se...|<SEC-DOCUMENT>000...|\n",
      "+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a95f506d-6591-4559-8303-b9a0ee55b84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split by <DOCUMENT> tag\n",
    "docs_df = raw_df.withColumn(\"raw_doc\", split(col(\"content\"), \"<DOCUMENT>\")) \\\n",
    "    .select(\n",
    "        col(\"filepath\"), # Keep the filepath so we know the source\n",
    "        explode(col(\"raw_doc\")).alias(\"doc_content\")\n",
    "    )\n",
    "\n",
    "# Filter out empty artifacts from the split\n",
    "docs_df = docs_df.filter(col(\"doc_content\").rlike(\"\\S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "222d73f7-e17a-4341-b0fb-9c0a3be7a16d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "docs_df.write.csv(\"docs_df\", header=True, mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d3c4184-73e8-4530-9588-7d2759e8abd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|            filepath|         doc_content|\n",
      "+--------------------+--------------------+\n",
      "|s3a://raw-data/se...|<SEC-DOCUMENT>000...|\n",
      "|s3a://raw-data/se...|\\n<TYPE>10-K\\n<SE...|\n",
      "|s3a://raw-data/se...|\\n<TYPE>EX-4.1\\n<...|\n",
      "|s3a://raw-data/se...|\\n<TYPE>EX-10.19\\...|\n",
      "|s3a://raw-data/se...|\\n<TYPE>EX-10.20\\...|\n",
      "|s3a://raw-data/se...|\\n<TYPE>EX-10.21\\...|\n",
      "|s3a://raw-data/se...|\\n<TYPE>EX-10.22\\...|\n",
      "|s3a://raw-data/se...|\\n<TYPE>EX-19.1\\n...|\n",
      "|s3a://raw-data/se...|\\n<TYPE>EX-21.1\\n...|\n",
      "|s3a://raw-data/se...|\\n<TYPE>EX-23.1\\n...|\n",
      "|s3a://raw-data/se...|\\n<TYPE>EX-31.1\\n...|\n",
      "|s3a://raw-data/se...|\\n<TYPE>EX-31.2\\n...|\n",
      "|s3a://raw-data/se...|\\n<TYPE>EX-32.1\\n...|\n",
      "|s3a://raw-data/se...|\\n<TYPE>EX-97.1\\n...|\n",
      "|s3a://raw-data/se...|\\n<TYPE>EX-101.SC...|\n",
      "|s3a://raw-data/se...|\\n<TYPE>EX-101.CA...|\n",
      "|s3a://raw-data/se...|\\n<TYPE>EX-101.DE...|\n",
      "|s3a://raw-data/se...|\\n<TYPE>EX-101.LA...|\n",
      "|s3a://raw-data/se...|\\n<TYPE>EX-101.PR...|\n",
      "|s3a://raw-data/se...|\\n<TYPE>GRAPHIC\\n...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 20 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/opt/spark/python/lib/pyspark.zip/pyspark/daemon.py\", line 233, in manager\n",
      "  File \"/opt/spark/python/lib/pyspark.zip/pyspark/daemon.py\", line 87, in worker\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n"
     ]
    }
   ],
   "source": [
    "docs_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87a7e3f7-da7f-41ff-9326-e769a73953a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered for 10-K reports.\n"
     ]
    }
   ],
   "source": [
    "# Extract the <TYPE> value\n",
    "docs_with_type = docs_df.withColumn(\n",
    "    \"report_type\", \n",
    "    regexp_extract(col(\"doc_content\"), r\"<TYPE>(.*?)\\n\", 1)\n",
    ")\n",
    "\n",
    "# Keep only the main 10-K report\n",
    "ten_k_df = docs_with_type.filter(col(\"report_type\").contains(\"10-K\"))\n",
    "\n",
    "print(\"Filtered for 10-K reports.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac8c071d-8cb7-4aca-b4d2-fad4aa66f13b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----------+\n",
      "|            filepath|         doc_content|report_type|\n",
      "+--------------------+--------------------+-----------+\n",
      "|s3a://raw-data/se...|\\n<TYPE>10-K\\n<SE...|       10-K|\n",
      "|s3a://raw-data/se...|\\n<TYPE>10-K\\n<SE...|       10-K|\n",
      "|s3a://raw-data/se...|\\n<TYPE>10-K\\n<SE...|       10-K|\n",
      "|s3a://raw-data/se...|\\n<TYPE>10-K\\n<SE...|       10-K|\n",
      "|s3a://raw-data/se...|\\n<TYPE>10-K\\n<SE...|       10-K|\n",
      "|s3a://raw-data/se...|\\n<TYPE>10-K\\n<SE...|       10-K|\n",
      "|s3a://raw-data/se...|\\n<TYPE>10-K\\n<SE...|       10-K|\n",
      "|s3a://raw-data/se...|\\n<TYPE>10-K\\n<SE...|       10-K|\n",
      "|s3a://raw-data/se...|\\n<TYPE>10-K\\n<SE...|       10-K|\n",
      "|s3a://raw-data/se...|\\n<TYPE>10-K\\n<SE...|       10-K|\n",
      "|s3a://raw-data/se...|\\n<TYPE>10-K\\n<SE...|       10-K|\n",
      "|s3a://raw-data/se...|\\n<TYPE>10-K\\n<SE...|       10-K|\n",
      "+--------------------+--------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ten_k_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "990ca626-57ab-44bb-aa95-aad03de7c649",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the cleaning function using BeautifulSoup\n",
    "def clean_html_content(html_text):\n",
    "    if not html_text:\n",
    "        return \"\"\n",
    "    # Parse HTML\n",
    "    soup = BeautifulSoup(html_text, \"html.parser\")\n",
    "    \n",
    "    # Remove script/style tags\n",
    "    for script in soup([\"script\", \"style\", \"noscript\"]):\n",
    "        script.decompose()\n",
    "    text = soup.get_text(separator=\" \")\n",
    "    return \" \".join(text.split())\n",
    "\n",
    "# Register as Spark UDF\n",
    "clean_udf = udf(clean_html_content, StringType())\n",
    "\n",
    "# Apply cleaning\n",
    "ten_k_df_cleaned = ten_k_df.withColumn(\"cleaned_text\", clean_udf(col(\"doc_content\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e189becb-7f57-412a-8ca9-c7493e697e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----------+--------------------+\n",
      "|            filepath|         doc_content|report_type|        cleaned_text|\n",
      "+--------------------+--------------------+-----------+--------------------+\n",
      "|s3a://raw-data/se...|\\n<TYPE>10-K\\n<SE...|       10-K|10-K 1 aapl-20240...|\n",
      "|s3a://raw-data/se...|\\n<TYPE>10-K\\n<SE...|       10-K|10-K 1 aapl-20250...|\n",
      "|s3a://raw-data/se...|\\n<TYPE>10-K\\n<SE...|       10-K|10-K 1 amzn-20231...|\n",
      "|s3a://raw-data/se...|\\n<TYPE>10-K\\n<SE...|       10-K|10-K 1 amzn-20241...|\n",
      "|s3a://raw-data/se...|\\n<TYPE>10-K\\n<SE...|       10-K|10-K 1 goog-20231...|\n",
      "|s3a://raw-data/se...|\\n<TYPE>10-K\\n<SE...|       10-K|10-K 1 goog-20241...|\n",
      "|s3a://raw-data/se...|\\n<TYPE>10-K\\n<SE...|       10-K|10-K 1 msft-20240...|\n",
      "|s3a://raw-data/se...|\\n<TYPE>10-K\\n<SE...|       10-K|10-K 1 msft-20250...|\n",
      "|s3a://raw-data/se...|\\n<TYPE>10-K\\n<SE...|       10-K|10-K 1 nflx-20231...|\n",
      "|s3a://raw-data/se...|\\n<TYPE>10-K\\n<SE...|       10-K|10-K 1 nflx-20241...|\n",
      "|s3a://raw-data/se...|\\n<TYPE>10-K\\n<SE...|       10-K|10-K 1 nvda-20240...|\n",
      "|s3a://raw-data/se...|\\n<TYPE>10-K\\n<SE...|       10-K|10-K 1 nvda-20250...|\n",
      "+--------------------+--------------------+-----------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ten_k_df_cleaned.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0697a0c8-0483-44f5-909b-bf1f4ce0a019",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 10:>                                                         (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+--------------------+\n",
      "|ticker|report_type|        cleaned_text|\n",
      "+------+-----------+--------------------+\n",
      "|  AAPL|       10-K|10-K 1 aapl-20240...|\n",
      "|  AAPL|       10-K|10-K 1 aapl-20250...|\n",
      "|  AMZN|       10-K|10-K 1 amzn-20231...|\n",
      "|  AMZN|       10-K|10-K 1 amzn-20241...|\n",
      "| GOOGL|       10-K|10-K 1 goog-20231...|\n",
      "| GOOGL|       10-K|10-K 1 goog-20241...|\n",
      "|  MSFT|       10-K|10-K 1 msft-20240...|\n",
      "|  MSFT|       10-K|10-K 1 msft-20250...|\n",
      "|  NFLX|       10-K|10-K 1 nflx-20231...|\n",
      "|  NFLX|       10-K|10-K 1 nflx-20241...|\n",
      "|  NVDA|       10-K|10-K 1 nvda-20240...|\n",
      "|  NVDA|       10-K|10-K 1 nvda-20250...|\n",
      "+------+-----------+--------------------+\n",
      "\n",
      "root\n",
      " |-- ticker: string (nullable = true)\n",
      " |-- report_type: string (nullable = false)\n",
      " |-- cleaned_text: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import regexp_extract, col, upper\n",
    "\n",
    "# pattern: .../AAPL/10-K/...\n",
    "ticker_pattern = r\"\\/([^\\/]+)\\/10-K\"\n",
    "\n",
    "final_df = ten_k_df_cleaned.withColumn(\n",
    "    \"ticker\", \n",
    "    upper(regexp_extract(col(\"filepath\"), ticker_pattern, 1))\n",
    ")\n",
    "\n",
    "output_df = final_df.select(\"ticker\", \"report_type\", \"cleaned_text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb059763-aa31-492e-a032-d3ce0092a2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result\n",
    "output_df.show()\n",
    "output_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "89b3a7ee-efb6-40b2-925c-7bb2d5984a19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logic defined.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import explode, monotonically_increasing_id\n",
    "from pyspark.sql.types import ArrayType, StringType, StructType, StructField, IntegerType\n",
    "\n",
    "def redact_pii(text):\n",
    "    if not text: return \"\"\n",
    "    # Regex to find email addresses\n",
    "    email_pattern = r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b'\n",
    "    # Regex to find phone numbers (simple US format)\n",
    "    phone_pattern = r'\\b\\d{3}[-.]?\\d{3}[-.]?\\d{4}\\b'\n",
    "    \n",
    "    text = re.sub(email_pattern, \"[EMAIL_REDACTED]\", text)\n",
    "    text = re.sub(phone_pattern, \"[PHONE_REDACTED]\", text)\n",
    "    return text\n",
    "\n",
    "# split text into 1000-character chunks with a little overlap.\n",
    "def chunk_text(text, chunk_size=1000, overlap=100):\n",
    "    if not text: return []\n",
    "    chunks = []\n",
    "    for i in range(0, len(text), chunk_size - overlap):\n",
    "        chunks.append(text[i:i + chunk_size])\n",
    "    return chunks\n",
    "\n",
    "# Register UDFs\n",
    "redact_udf = udf(redact_pii, StringType())\n",
    "chunk_udf = udf(chunk_text, ArrayType(StringType()))\n",
    "\n",
    "print(\"Logic defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3584117a-cc52-459a-b4e7-67f362d798d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "redacted_df = output_df.withColumn(\"redacted_text\", redact_udf(col(\"cleaned_text\")))\n",
    "\n",
    "chunked_df = redacted_df.withColumn(\"text_chunks\", chunk_udf(col(\"redacted_text\")))\n",
    "\n",
    "# chunks so each chunk gets its own row for the LLM\n",
    "final_chunks_df = chunked_df.select(\n",
    "    \"ticker\", \n",
    "    \"report_type\", \n",
    "    explode(col(\"text_chunks\")).alias(\"chunk_content\")\n",
    ").withColumn(\"chunk_id\", monotonically_increasing_id())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7e47b9d3-2c14-4330-9235-ff939f30710d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+--------------------+--------------------+\n",
      "|ticker|report_type|        cleaned_text|       redacted_text|\n",
      "+------+-----------+--------------------+--------------------+\n",
      "|  AAPL|       10-K|10-K 1 aapl-20240...|10-K 1 aapl-20240...|\n",
      "|  AAPL|       10-K|10-K 1 aapl-20250...|10-K 1 aapl-20250...|\n",
      "|  AMZN|       10-K|10-K 1 amzn-20231...|10-K 1 amzn-20231...|\n",
      "|  AMZN|       10-K|10-K 1 amzn-20241...|10-K 1 amzn-20241...|\n",
      "| GOOGL|       10-K|10-K 1 goog-20231...|10-K 1 goog-20231...|\n",
      "| GOOGL|       10-K|10-K 1 goog-20241...|10-K 1 goog-20241...|\n",
      "|  MSFT|       10-K|10-K 1 msft-20240...|10-K 1 msft-20240...|\n",
      "|  MSFT|       10-K|10-K 1 msft-20250...|10-K 1 msft-20250...|\n",
      "|  NFLX|       10-K|10-K 1 nflx-20231...|10-K 1 nflx-20231...|\n",
      "|  NFLX|       10-K|10-K 1 nflx-20241...|10-K 1 nflx-20241...|\n",
      "|  NVDA|       10-K|10-K 1 nvda-20240...|10-K 1 nvda-20240...|\n",
      "|  NVDA|       10-K|10-K 1 nvda-20250...|10-K 1 nvda-20250...|\n",
      "+------+-----------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "redacted_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4d6d7ed6-d85e-49ea-abea-380d93251a40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Chunks Generated: 4269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 26:>                                                         (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+--------------------------------------------------+--------+\n",
      "|ticker|report_type|                                     chunk_content|chunk_id|\n",
      "+------+-----------+--------------------------------------------------+--------+\n",
      "|  AAPL|       10-K|10-K 1 aapl-20240928.htm 10-K aapl-20240928 fal...|       0|\n",
      "|  AAPL|       10-K|urrent http://fasb.org/us-gaap/2024#OtherLiabil...|       1|\n",
      "|  AAPL|       10-K| 2024-09-28 [PHONE_REDACTED] aapl:A0.500Notesdu...|       2|\n",
      "|  AAPL|       10-K|nalPaidInCapitalMember 2022-09-24 [PHONE_REDACT...|       3|\n",
      "|  AAPL|       10-K| us-gaap:RetainedEarningsMember 2024-09-28 [PHO...|       4|\n",
      "+------+-----------+--------------------------------------------------+--------+\n",
      "only showing top 5 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):                                              \n",
      "  File \"/opt/spark/python/lib/pyspark.zip/pyspark/daemon.py\", line 233, in manager\n",
      "  File \"/opt/spark/python/lib/pyspark.zip/pyspark/daemon.py\", line 87, in worker\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n"
     ]
    }
   ],
   "source": [
    "# Show the result\n",
    "print(f\"Total Chunks Generated: {final_chunks_df.count()}\")\n",
    "final_chunks_df.show(5, truncate=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b750ae36-1859-4920-8aef-8b2da901508a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26/01/08 17:49:27 WARN Base64: JAXB is unavailable. Will fallback to SDK implementation which may be less performant.If you are using Java 9+, you will need to include javax.xml.bind:jaxb-api as a dependency.\n",
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success! Data saved to s3a://raw-data/processed-data\n"
     ]
    }
   ],
   "source": [
    "# Write to the 'processed-data' folder\n",
    "output_path = \"s3a://raw-data/processed-data\"\n",
    "\n",
    "final_chunks_df.write \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .partitionBy(\"ticker\") \\\n",
    "    .parquet(output_path)\n",
    "\n",
    "print(f\"Success! Data saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba76ff8-0b13-49ca-82a9-3bf26914f633",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5d297f-02c6-44ef-a385-a33689cc31f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ee3bb3d3-7e3c-4f69-b67d-aa773b7e31d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read back the processed data\n",
    "gold_df = spark.read.parquet(\"s3a://raw-data/processed-data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "867c69dd-a0b2-4759-94e9-9c00232b3cd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- report_type: string (nullable = true)\n",
      " |-- chunk_content: string (nullable = true)\n",
      " |-- chunk_id: long (nullable = true)\n",
      " |-- ticker: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gold_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "14010c5b-ec8c-4605-b6ee-6e7841c6ea12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Chunks Available: 4269\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total Chunks Available: {gold_df.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a44c5804-4243-4a98-96b2-f9550f95df1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|ticker|count|\n",
      "+------+-----+\n",
      "|  NVDA|  813|\n",
      "| GOOGL|  842|\n",
      "|  AMZN|  695|\n",
      "|  NFLX|  601|\n",
      "|  AAPL|  492|\n",
      "|  MSFT|  826|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gold_df.groupBy(\"ticker\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1083bf7-1a58-4766-998a-06e2ca39db13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
